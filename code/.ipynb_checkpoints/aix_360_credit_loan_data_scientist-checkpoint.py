# -*- coding: utf-8 -*-
"""AIX 360-Credit Loan Approval (Data Scientist Explaination).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12IwxXr1e1V9IavWOWmUcRUGcyYscA6PF

# **Install AIX 360 through pip**
"""

!pip install aix360

##Download the dataset by filling the google form here, an email will be sent to your
##registered email-id. Upload it to colab notebook and move those dataset in the given location
! mv /content/heloc_dataset_v1.csv /usr/local/lib/python3.6/dist-packages/aix360/data/heloc_data/heloc_dataset.csv

import pandas as pd
data_dictionary = pd.read_excel("/content/heloc_data_dictionary-2.xlsx")
data_dictionary

"""# **Load the dataset**"""

# Load FICO HELOC data with special values converted to np.nan
from aix360.datasets.heloc_dataset import HELOCDataset, nan_preprocessing
data = HELOCDataset(custom_preprocessing=nan_preprocessing).data()
# Separate target variable
y = data.pop('RiskPerformance')
# Split data into training and test sets using fixed random seed
from sklearn.model_selection import train_test_split
dfTrain, dfTest, yTrain, yTest = train_test_split(data, y, random_state=0, stratify=y)
dfTrain.head().transpose()

"""# **Binarize the values for alogrithms**"""

# Binarize data and also return standardized ordinal features
from aix360.algorithms.rbm import FeatureBinarizer
fb = FeatureBinarizer(negations=True, returnOrd=True)
##return standardized versions of the original unbinarized ordinal features, which are used by LogRR but not BRCG
dfTrain, dfTrainStd = fb.fit_transform(dfTrain)
dfTest, dfTestStd = fb.transform(dfTest)
#Below is the result of binarizing the first 'ExternalRiskEstimate' feature.
dfTrain['ExternalRiskEstimate'].head()

"""# **Fit and Test Boolean Run Column Generation Model to Training Dataset**"""

# Instantiate BRCG with small complexity penalty and large beam search width
from aix360.algorithms.rbm import BooleanRuleCG
# The model complexity parameters lambda0 and lambda1 penalize the number of clauses in the
#rule and the number of conditions in each clause. 
# We use the default values of 1e-3 for lambda0 and lambda1 
#(decreasing them did not increase accuracy here) and leave other parameters at their defaults as well. 
# The model is then trained, evaluated, and printed.
br = BooleanRuleCG(lambda0=1e-3, lambda1=1e-3, CNF=True)

# Train, print, and evaluate model
br.fit(dfTrain, yTrain)
from sklearn.metrics import accuracy_score
print('Training accuracy:', accuracy_score(yTrain, br.predict(dfTrain)))
print('Test accuracy:', accuracy_score(yTest, br.predict(dfTest)))
print('Predict Y=0 if ANY of the following rules are satisfied, otherwise Y=1:')
print(br.explain()['rules'])

"""Here, ExternalRiskEstimate reprsents consolidated version of risk markers(higher is better)and NumSatisfactoryTrades represents number of satisfactory credit accounts. If the value of y is a "1" then the person defaulted on the loan. If the value is a "0" then the person paid back the loan. Point to be noted that with these two clauses including the same features, we are able to generate a pretty decent accuracy of 69.65%

# **Fit and test Logistic Rule Regression(LogRR) on training data.**
"""

# Instantiate LRR with good complexity penalties and numerical features
from aix360.algorithms.rbm import LogisticRuleRegression
# Here we are also including unbinarized ordinal features (useOrd=True) in addition to rules. 
# Similar to BRCG, the complexity parameters lambda0, lambda1 penalize the number of rules included in the model and the number of conditions in each rule. 
# The values for lambda0, lambda1 below strike a good balance between accuracy and model complexity.

lrr = LogisticRuleRegression(lambda0=0.005, lambda1=0.001, useOrd=True)

# Train, print, and evaluate model
lrr.fit(dfTrain, yTrain, dfTrainStd)
print('Training accuracy:', accuracy_score(yTrain, lrr.predict(dfTrain, dfTrainStd)))
print('Test accuracy:', accuracy_score(yTest, lrr.predict(dfTest, dfTestStd)))
print('Probability of Y=1 is predicted as logistic(z) = 1 / (1 + exp(-z))')
print('where z is a linear combination of the following rules/numerical features:')
lrr.explain()

"""# **Visualize LogRR model as a Generalized Additive Model (GAM)**"""

dfx = lrr.explain()
# Separate 1st-degree rules into (feature, operation, value) to count unique features
dfx2 = dfx['rule/numerical feature'].str.split(' ', expand=True)
dfx2.columns = ['feature','operation','value']
dfx2['feature'].nunique() # includes intercept

"""It follows that there are 14(excluding intercept) functions to plot, which we organize into semantic groups below to ease interpretation.

### **1. ExternalRiskEstimate**
As  shown above in BRCG model, 'ExternalRiskEstimate' is positively related with good credit risk. The sudden hike in plot at 72, is additional to it.
"""

lrr.visualize(data, fb, ['ExternalRiskEstimate']);

"""### **2. Credit inquiries**
The next two plots illustrate the dependence on the applicant's credit inquiries. 



The first plot shows a significant penalty for having less than one month since the most recent inquiry ('MSinceMostRecentInqexcl7days' = 0).

"""

lrr.visualize(data, fb, ['MSinceMostRecentInqexcl7days']);

"""

The second shows that predicted risk increases with the number of inquiries in the last six months ('NumInqLast6M').

"""

lrr.visualize(data, fb, ['NumInqLast6M']);

"""### **3. Debt Level**

The following four plots relate to the applicant's debt level. 

'NetFractionRevolvingBurden' is revolving balance divided by the credit limit and is negatively correlated with probability of good credit.
"""

lrr.visualize(data, fb, ['NetFractionRevolvingBurden']);

"""The second 'NumBank2NatlTradesWHighUtilization' plot shows that the number of accounts ("trades") with high utilization (high balance relative to credit limit for each account) also has a large negative impact, with a drop as soon as one account has high utilization."""

lrr.visualize(data, fb, ['NumBank2NatlTradesWHighUtilization']);

"""

The third plot shows that the model gives a bonus to applicants who carry balances on no more than five revolving debt accounts.
"""

lrr.visualize(data, fb, ['NumRevolvingTradesWBalance']);

"""

The fourth shows an effect from the percentage of accounts with a balance that is much smaller than those from other features.
"""

lrr.visualize(data, fb, ['PercentTradesWBalance']);

"""
### **4. Number and type of accounts**

The number of "satisfactory" accounts ("trades") has a significant positive effect on the predicted probability of good credit, with jumps at 12 and 17 accounts.
"""

lrr.visualize(data, fb, ['NumSatisfactoryTrades']);

"""

However, having more than 40% as installment debt accounts (e.g. car loans) is seen as a negative.
"""

lrr.visualize(data, fb, ['PercentInstallTrades']);

"""### **5. Length of credit history**

The 'AverageMInFile' plot shows that most of the benefit of having a longer average credit history accrues between average ages of 52 and 84 months (four to seven years).

"""

lrr.visualize(data, fb, ['AverageMInFile']);

"""

Similar but smaller gains come when the age of the oldest account ('MSinceOldestTradeOpen') exceeds 122 and 146 months (10-12 years).
"""

lrr.visualize(data, fb, ['MSinceOldestTradeOpen']);

"""
### **6. Delinquencies**

The last set of plots looks at the effect of delinquencies. The first plot shows that much of the change due to the percentage of accounts that were never delinquent ('PercentTradesNeverDelq') occurs between 90% and 100%.
"""

lrr.visualize(data, fb, ['PercentTradesNeverDelq']);

"""MaxDelq2PublicRecLast12M' measures the severity of the applicant's worst delinquency from the last 12 months of the public record. A value of 5 or below indicates that some delinquency has occurred, whether of unknown duration, 30/60/90/120 days delinquent, or a derogatory comment."""

lrr.visualize(data, fb, ['MaxDelq2PublicRecLast12M']);

"""According to the last 'MSinceMostRecentDelq' plot, the effect of the most recent delinquency wears off after 21 months.

"""

lrr.visualize(data, fb, ['MSinceMostRecentDelq']);

