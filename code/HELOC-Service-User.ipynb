{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELOC Service User\n",
    "\n",
    "The objective is to provide a Service User / Customer seeking a loan information on:  \n",
    "* important factors in their application,  \n",
    "* comparison with applications having similar financial attributes, and  \n",
    "* corrective measures that the applicant can undertake should the application be rejected.\n",
    "\n",
    "It is intended that the Loan Officer will use this notebook to assist them respond to inquiries from a (potential) customer.\n",
    "\n",
    "## ContrastiveExplanation\n",
    "This notebook uses the `ContrastiveExplanation` Python package, created by Marcel Robeer, University of Utrecht.  It is necessary to clone the repository: \n",
    "https://github.com/MarcelRobeer/ContrastiveExplanation   \n",
    "Please ensure that the current working directory contains the `contrastive_explanation` subdirectory.  \n",
    "For further information, see:  \n",
    "https://pythonawesome.com/contrastive-explanation-foil-trees-developed-at-tno-utrecht-university/\n",
    "\n",
    "###### Contents\n",
    "1. [Feature-focused Model](#feature-focused)\n",
    "\n",
    "2. [Case-based Profiles](#case-profile)\n",
    "\n",
    "3. [Corrective Measures](#corrective-measures)\n",
    "---\n",
    "\n",
    "Set a seed for reproducibility, and import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import urllib.request\n",
    "import pprint\n",
    "\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import datasets, model_selection, ensemble, metrics, pipeline, preprocessing\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import DecisionListClassifier\n",
    "from interpret.glassbox import LogisticRegression\n",
    "from interpret import show\n",
    "\n",
    "seed = 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For printing out the features and their corresponding values of an instance we define a function `print_sample()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by Marcel Robeer, University of Utrecht\n",
    "def print_sample(feature_names, sample):\n",
    "    print('\\n'.join(f'{name}: {value}' for name, value in zip(feature_names, sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Feature-focused Model <a name=\"feature-focused\"></a>\n",
    "\n",
    "Using the Home Equity Loan [HELOC](https://community.fico.com/s/explainable-machine-learning-challenge?tabset-158d9=3) data set (as also used in the FICO Explainability Challenge). \n",
    "\n",
    "1. Load the data set (and select features with greatest overall mean absolute score)  \n",
    "2. Train an Explainable Boosting Machine model on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load dataset as Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/JJCoen/Interpretable-ML-Models/master/data/train_imp.csv'\n",
    "train = pd.read_csv(url)\n",
    "del train['Unnamed: 0']\n",
    "\n",
    "url2 = 'https://raw.githubusercontent.com/JJCoen/Interpretable-ML-Models/master/data/test_imp.csv'\n",
    "test = pd.read_csv(url2)\n",
    "del test['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the top ten features identified by the Data Scientist.  Restricting the machine learning model to 10 features is to facilitate the formulation of corrective measures using the Constrastive Explanations package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('../data/top-10.csv')\n",
    "feat_df = pd.read_csv(filepath, index_col=False, header=0)\n",
    "feat_select = feat_df['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names:  ['Bad' 'Good']\n",
      "Label names, reference level first:  ['Good', 'Bad']\n"
     ]
    }
   ],
   "source": [
    "# train / test split\n",
    "label = train.columns[0]\n",
    "print(\"Label names: \", train[label].unique() )\n",
    "label_names = ['Good', 'Bad']\n",
    "print(\"Label names, reference level first: \", label_names )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of the list `label_names` needs to be the reference (0) level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RiskPerformance\n",
      "Bad     3852\n",
      "Good    3551\n",
      "dtype: int64\n",
      "RiskPerformance\n",
      "Bad     1284\n",
      "Good    1184\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class distribution\n",
    "print(train.groupby('RiskPerformance').size())\n",
    "print(test.groupby('RiskPerformance').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7403, 10)\n",
      "0     Bad\n",
      "1     Bad\n",
      "2    Good\n",
      "3    Good\n",
      "4    Good\n",
      "Name: RiskPerformance, dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: RiskPerformance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split-out labels in train\n",
    "X_train = train[feat_select]\n",
    "y_train = train[label].apply(lambda x: 0 if x == \"Good\" else 1) #Turning response into 0 and 1\n",
    "print(X_train.shape)\n",
    "print(train[label].head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2468, 10)\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: RiskPerformance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split out labels in test\n",
    "X_test = test[feat_select]\n",
    "y_test = test[label].apply(lambda x: 0 if x == \"Good\" else 1) #Turning response into 0 and 1\n",
    "print(X_test.shape)\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Explainable Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExplainableBoostingClassifier(binning='quantile', early_stopping_rounds=50,\n",
       "                              early_stopping_tolerance=0.0001,\n",
       "                              feature_names=['MSinceMostRecentInqexcl7days',\n",
       "                                             'ExternalRiskEstimate',\n",
       "                                             'NetFractionRevolvingBurden',\n",
       "                                             'AverageMInFile',\n",
       "                                             'NumBank2NatlTradesWHighUtilization',\n",
       "                                             'MSinceOldestTradeOpen',\n",
       "                                             'MaxDelq2PublicRecLast12M',\n",
       "                                             'PercentTradesWBalance',\n",
       "                                             'PercentTradesNev...\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'interaction', 'interaction',\n",
       "                                             'interaction', 'interaction',\n",
       "                                             'interaction', 'interaction',\n",
       "                                             'interaction', 'interaction',\n",
       "                                             'interaction', 'interaction'],\n",
       "                              inner_bags=0, interactions=10, learning_rate=0.01,\n",
       "                              mains='all', max_bins=256,\n",
       "                              max_interaction_bins=32, max_leaves=3,\n",
       "                              max_rounds=5000, min_samples_leaf=2, n_jobs=-1,\n",
       "                              outer_bags=8, random_state=2024,\n",
       "                              validation_size=0.15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "ebm = ExplainableBoostingClassifier(random_state=2024, n_jobs=-1)\n",
    "ebm.fit(X_train, y_train)   #Works on dataframes and numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier performance (F1): 0.7334120811183514\n"
     ]
    }
   ],
   "source": [
    "# Print out the classifier performance (F1-score)\n",
    "print('Classifier performance (F1):', metrics.f1_score(y_test, ebm.predict(X_test), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Case-based Profiles <a name=\"case-profile\"></a>\n",
    "\n",
    "**Cases similar to the one under consideration**\n",
    "\n",
    "Consider the first instance in the test set.  \n",
    "1. Identify the decision rule that applies to the specific case.  \n",
    "2. Select similar cases based on the decision rule predicates and feature values of the case.  \n",
    "3. Use EBM model to make predictions on the similar cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimco\\anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:28: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  warnings.warn(\"The module is deprecated in version 0.21 and will be removed \"\n",
      "C:\\Users\\jimco\\anaconda3\\lib\\site-packages\\interpret\\visual\\udash.py:5: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "C:\\Users\\jimco\\anaconda3\\lib\\site-packages\\interpret\\visual\\udash.py:6: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "C:\\Users\\jimco\\anaconda3\\lib\\site-packages\\interpret\\visual\\udash.py:7: UserWarning: \n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n",
      "  import dash_table as dt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7166/2178625766976/ -->\n",
       "<iframe src=\"http://127.0.0.1:7166/2178625766976/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 2022\n",
    "dl = DecisionListClassifier(random_state=seed)\n",
    "dl.fit(X_train, y_train)\n",
    "\n",
    "dl_local = dl.explain_local(X_test[0:1], y_test[0:1])\n",
    "\n",
    "show(dl_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature values for the first test instance / loan application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSinceMostRecentInqexcl7days            0.0\n",
      "ExternalRiskEstimate                   59.0\n",
      "NetFractionRevolvingBurden             62.0\n",
      "AverageMInFile                         78.0\n",
      "NumBank2NatlTradesWHighUtilization      3.0\n",
      "MSinceOldestTradeOpen                 137.0\n",
      "MaxDelq2PublicRecLast12M                4.0\n",
      "PercentTradesWBalance                  94.0\n",
      "PercentTradesNeverDelq                 91.0\n",
      "MSinceMostRecentDelq                    1.0\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Logical indexing to identify similar cases\n",
    "similar_cases = X_test[(X_test.MSinceMostRecentInqexcl7days <= 1) \n",
    "       & (X_test.ExternalRiskEstimate <= 65) \n",
    "      & (X_test.NetFractionRevolvingBurden > 60)\n",
    "      & (X_test.AverageMInFile > 70)\n",
    "      & (X_test.NumBank2NatlTradesWHighUtilization == 3.0)\n",
    "      & (X_test.MSinceOldestTradeOpen > 130.0)\n",
    "      & (X_test.MaxDelq2PublicRecLast12M == 4.0)\n",
    "      & (X_test.PercentTradesWBalance > 90.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <th>AverageMInFile</th>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <th>MaxDelq2PublicRecLast12M</th>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>78</td>\n",
       "      <td>3.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>76</td>\n",
       "      <td>3.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>80</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0.506368</td>\n",
       "      <td>59.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>92</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(similar_cases.to_html)\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(similar_cases.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cases above had predictions:  [1 1 1 1 1]  respectively\n"
     ]
    }
   ],
   "source": [
    "print(\"The cases above had predictions: \", ebm.predict(similar_cases), \" respectively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Corrective Measures <a name=\"corrective-measures\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Contrastive Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, the third application in the test set had the loan rejected (predicted to default).\n",
    "\n",
    "Perform contrastive explanation on the third test instance (X_test[:, 2]) by wrapping the dataframe in a DomainMapper, and then using method ContrastiveExplanation.explain_instance_domain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSinceMostRecentInqexcl7days: 0.0\n",
      "ExternalRiskEstimate: 72.0\n",
      "NetFractionRevolvingBurden: 43.0\n",
      "AverageMInFile: 53.0\n",
      "NumBank2NatlTradesWHighUtilization: 3.0\n",
      "MSinceOldestTradeOpen: 84.0\n",
      "MaxDelq2PublicRecLast12M: 7.0\n",
      "PercentTradesWBalance: 64.0\n",
      "PercentTradesNeverDelq: 100.0\n",
      "MSinceMostRecentDelq: 32.6627197015183\n"
     ]
    }
   ],
   "source": [
    "# Contrastive explanation\n",
    "# Import\n",
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain ('questioned data point') why it predicted the fact instead of the foil \n",
    "sample = X_test.iloc[2]\n",
    "print_sample(feat_select, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The model predicted 'Bad' instead of 'Good' because 'MSinceMostRecentInqexcl7days <= 2.296 and NumBank2NatlTradesWHighUtilization > 1.59'\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a domain mapper (map the explanation to meaningful labels for explanation)\n",
    "dm = ce.domain_mappers.DomainMapperPandas(X_train,\n",
    "                                           contrast_names=label_names)\n",
    "\n",
    "# Create the contrastive explanation object (default is a Foil Tree explanator)\n",
    "exp = ce.ContrastiveExplanation(dm)\n",
    "\n",
    "# Explain the instance (sample) for the given model\n",
    "exp.explain_instance_domain(ebm.predict_proba, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted class using the ExplainableBoostingMachine was ‘Bad’, while the 'Good' class may have been expected instead. The difference of why the current instance was classified ‘Bad’ is because its `MSinceMostRecentInqexcl7days` is less than or equal to 2.296 and `NumBank2NatlTradesWHighUtilization` is greater than 1.59.   \n",
    "\n",
    "In other words, if the instance would change the `MSinceMostRecentInqexcl7days` to more than 2.296 and `NumBank2NatlTradesWHighUtilization` to less than 1.59, the EBM classifier would have changed the outcome to ‘Good’.\n",
    "\n",
    "The cell below is provided in order to make changes suggested by the results of the Contrastive Explanation.  This enables a loan applicant to make changes in order to get approval (\"nondefault\" / 0 classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dict = {\"MSinceMostRecentInqexcl7days\": 7.0,\n",
    "\"ExternalRiskEstimate\": 72.0,\n",
    "\"NetFractionRevolvingBurden\": 43.0,\n",
    "\"AverageMInFile\": 53.0,\n",
    "\"NumBank2NatlTradesWHighUtilization\": 1.0,\n",
    "\"MSinceOldestTradeOpen\": 84.0,\n",
    "\"MaxDelq2PublicRecLast12M\": 7.0,\n",
    "\"PercentTradesWBalance\": 64.0,\n",
    "\"PercentTradesNeverDelq\": 100.0,\n",
    "\"MSinceMostRecentDelq\": 32.6627197015183}\n",
    "sample_update = pd.Series(sample_dict)\n",
    "X_test_update = pd.DataFrame([sample_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7166/2178668450960/ -->\n",
       "<iframe src=\"http://127.0.0.1:7166/2178668450960/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebm_local = ebm.explain_local(X_test_update)\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the loan applicant is receiving a \"Good\" (0) classification.  \n",
    "Let the money roll!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The model predicted 'Good' instead of 'Bad' because 'MSinceMostRecentInqexcl7days > 4.977'\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explain the instance (sample) for the given model\n",
    "exp.explain_instance_domain(ebm.predict_proba, sample_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to apply corrective measures since the desired outcome has been achieved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
